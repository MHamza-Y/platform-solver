{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from os.path import join\n",
    "from os.path import dirname\n",
    "from src.components.eval import eval_env\n",
    "from src.components.train import train_env\n",
    "from src.components.tune import tune_hyper_param\n",
    "from src.envs.creator import env_creator\n",
    "from src.envs.creator import register_platform_env\n",
    "from src.files.utills import pickle_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Configs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_workers = 12\n",
    "num_envs_per_worker = 24\n",
    "algo = \"PPO\"\n",
    "env_name = \"Platform-v0\"\n",
    "register_platform_env(env_name)\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env_name)\n",
    "    .training(gamma=0.995, num_sgd_iter=10, sgd_minibatch_size=1000, clip_param=0.1, lr=1e-4, train_batch_size=2000,\n",
    "              entropy_coeff=1e-4)\n",
    "    .resources(num_gpus=1, num_cpus_per_worker=1)\n",
    "    .rollouts(num_rollout_workers=total_workers, num_envs_per_worker=num_envs_per_worker)\n",
    "    .framework(\"torch\")\n",
    "    .training(\n",
    "        model={\"fcnet_hiddens\": [64, 64, 64], \"vf_share_layers\": False, \"use_lstm\": tune.grid_search([True, False]),\n",
    "               \"lstm_cell_size\": 32,\n",
    "               \"max_seq_len\": 5})\n",
    "    .evaluation(evaluation_num_workers=1)\n",
    ")\n",
    "log_dir = \"tmp/pipeline_logs\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tune Hyper-parameters\n",
    "\n",
    "The hyper-parameters to be optimized can be defined in the config using tune API. For example in this case *use_lstm* is a hyper-parameter with values *[True, False]*. The *tune_hyper_param*  searches for the optimal parameter values and returns the best config."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tune_results = tune_hyper_param(\n",
    "    algo=algo,\n",
    "    config=config,\n",
    "    log_dir=log_dir,\n",
    "    iterations=30,\n",
    "    name=\"platform_solver_tuning\"\n",
    ")\n",
    "\n",
    "best_config = tune_results.get_best_result(metric=\"episode_reward_mean\", mode=\"max\").config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train RL Agent\n",
    "\n",
    "The model is trained here using the best config from the tune step. The best training checkpoint is then chosen for evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_results = train_env(\n",
    "    algo=algo,\n",
    "    config=best_config,\n",
    "    log_dir=log_dir,\n",
    "    iterations=200,\n",
    "    stop_reward_mean=1,\n",
    "    name=\"platform_solver\"\n",
    ")\n",
    "best_checkpoint = train_results.get_best_result(metric=\"episode_reward_mean\", mode=\"max\").best_checkpoints[0]\n",
    "best_checkpoint_path = best_checkpoint[0]._local_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Trained Agent\n",
    "\n",
    "The best checkpoint is evaluated for and the results are returned as dataframe for further interpretations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(best_checkpoint_path)\n",
    "start = time.time()\n",
    "results = eval_env(ray=ray, epochs=1000, workers=8, env_creator=env_creator, env_kwargs=dict(env_config=''),\n",
    "                   checkpoint_path=best_checkpoint_path)\n",
    "print(time.time() - start)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pickle_obj(results,join('tmp','evaluation_results.pkl'))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
